=================== Python Configuration ==========================
$ conda create --name {env_name}
$ conda env list
$ conda activate {env_name}
$ conda deactivate
================== Image resize =============================
from torchvision import transforms
def trnasformMS(height, width, PILimage):
    new_width, new_height = width, height
    resize_transform = transforms.Resize((new_height, new_width))
    resized_image = resize_transform(PILimage)
    return resized_image
======================= Calculate number of parameters (M) in a model =========================
num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
num_params = num_params / 1000000
===================Compare model prediction with ground truth label==================================================
x, y = batch
prediction = model(x)
_, predicted = torch.max(prediction.data, 1)
if prediction == y:
  print('Matched with label: ', y)
================= Use multiple GPUs for training in PyTorch ===========================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device_ids = [0, 1, 2, 3]
network = nn.DataParallel(network, device_ids=device_ids).to(device)
  ================extract features of image===================================
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
resnet18 = models.resnet18(pretrained=True)
resnet18.eval()
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
image = Image.open('uniud.JPG')
input_tensor = preprocess(image)
input_batch = input_tensor.unsqueeze(0)  # create a mini-batch as expected by the model
with torch.no_grad():
    features = resnet18(input_batch)
print(features.shape)
============Multidimensional scaling (MDS)=============================================
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import MDS
dissimilarity_matrix = np.array([
    [0, 1, 2],
    [1, 0, 3],
    [2, 3, 0]
])
# Compute the MDS embedding
mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)
X_mds = mds.fit_transform(dissimilarity_matrix)
plt.scatter(X_mds[:, 0], X_mds[:, 1], c=[2,3,4], cmap='viridis')
plt.show()
====================Draw multiple lines on in a single graph=====================
import matplotlib.pyplot as plt
  
x = [0, 2, 4, 6, 8, 10, 12, 14, 16]
y1 = [0, 30, 60, 100, 200, 280, 392, 502, 630]
y2 = [0, 252, 493, 762, 1004, 1485, 1998, 2278, 2750]
y3 = [0, 10, 48, 100, 200, 300, 400, 550, 700]
y4 = [0, 250, 500, 620, 860, 1175, 1325, 1650, 1940]
plt.plot(x, y1, label = 'CNN-2 without FHE')
plt.plot(x, y2, label = 'CNN-2 with FHE')
plt.plot(x, y3, label = 'LeNet-1 without FHE')
plt.plot(x, y4, label = 'LeNet-1 with FHE')
plt.legend()
plt.xlabel('Number of clients (N)', fontsize=12)
plt.ylabel('Time (s)', fontsize=12)
plt.title('Model training with and without FHE.', fontsize=12)
plt.savefig('fhe_time.pdf')
plt.show()
======================== Read hdf5 file in python =======================
import h5py
import os
with h5py.File(os.path.join('train_val_split', 'art_painting_test.hdf5'), "r") as f:
    print("Keys: %s" % f.keys())
    a_group_key = list(f.keys())[0]
    # print(type(f[a_group_key])) 
    data = list(f[a_group_key])
    # print(data[0].shape)   # shape of one image, e.g. (227, 227, 3)
    # preferred methods to get dataset values:
    ds_obj = f[a_group_key]      # returns as a h5py dataset object
    ds_arr = f[a_group_key][()]  # returns as a numpy array
    # print('ds_arr: ', ds_arr.shape)    # (2048, 227, 227, 3)
=========================== Kill a process using GPU ============================
$ kill -9 <PID>
